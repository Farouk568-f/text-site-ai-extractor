# ğŸš€ Text Site AI Extractor

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

An advanced Arabic text extraction API that intelligently removes duplicates and unwanted content from web articles, providing clean and organized text output.

## âœ¨ Features

### ğŸ”§ Advanced Text Processing
- **Duplicate Removal**: Smart algorithm using `difflib.SequenceMatcher` to detect and remove similar content
- **Content Filtering**: Removes UI elements, comments, and navigation components
- **Text Cleaning**: Eliminates extra spaces, symbols, and unwanted characters

### ğŸ“ Customizable Options
- **Minimum Text Length**: Configurable threshold (default: 100 characters)
- **Smart Filtering**: Ignores overly short or long text segments
- **Advanced Search**: Prioritizes main content areas

### ğŸŒ Multiple Endpoints
- `/search-articles/` - Search and extract from multiple articles
- `/extract-single/` - Extract text from a single URL
- `/health` - API health check

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run the API
```bash
python article_api.py
```

The API will run on port 5001

### 3. Test the API
```bash
python test_improved_api.py
```

## ğŸ“ Usage Examples

### Search Articles with Custom Minimum Length

```python
import requests

# Search with minimum length 1000 (complete and clean content)
payload = {
    "query": "Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
    "min_length": 1000  # As requested - complete and clean content
}

response = requests.post("http://localhost:5001/search-articles/", json=payload)
result = response.json()

print(f"Successful articles: {result['successful_articles']}")
print(f"Minimum length used: {result['min_length_used']}")
```

### Extract Text from Single URL

```python
import requests

# Extract text from URL with minimum length 1000
payload = {
    "url": "https://sdaia.gov.sa/ar/SDAIA/about/Pages/AboutAI.aspx",
    "min_length": 1000
}

response = requests.post("http://localhost:5001/extract-single/", json=payload)
result = response.json()

if result["status"] == "success":
    print(f"Paragraphs: {result['paragraphs_count']}")
    print(f"Text length: {result['text_length']}")
    print(f"Text: {result['text'][:200]}...")
```

## âš™ï¸ Configuration Options

### Minimum Text Length

| Value | Result |
|-------|--------|
| `100` | Short content (default) |
| `500` | Medium content |
| `1000` | **Complete and clean content (recommended)** |
| `2000` | Very long content |

### Optimal Usage Example

```python
# For complete and clean content as requested
payload = {
    "query": "Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
    "min_length": 1000  # This will give you complete and clean content
}
```

## ğŸ” How It Works

### 1. Remove Unwanted Elements
- `nav`, `header`, `footer`, `aside`
- `script`, `style`, `noscript`
- `.navigation`, `.menu`, `.sidebar`
- `.ads`, `.comments`, `.related`

### 2. Find Main Content
```python
selectors = [
    'article', 'main', 
    '[role="main"]', 
    '.post-content', '.article-content', '.entry-content',
    '#content', '#main-content', '#article-content'
]
```

### 3. Text Filtering
- Remove very short text (< 30 characters)
- Remove very long text (> 2000 characters)
- Remove UI elements
- Remove links and symbols

### 4. Duplicate Removal
- Uses `difflib.SequenceMatcher`
- Similarity threshold: 70%
- Ignores short paragraphs (< 50 characters)

## ğŸ“Š Results Comparison

### Before Improvement
```
Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠSDAIAØ§Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ø³Ø¯Ø§ÙŠØ§Ø¹Ù† Ø³Ø¯Ø§ÙŠØ§Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠSDAIAØ§Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ø³Ø¯Ø§ÙŠØ§Ø¹Ù† Ø³Ø¯Ø§ÙŠØ§Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
Ù‡Ù„ Ø§Ø³ØªÙØ¯Øª Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø©ØŸÙ†Ø¹Ù…Ù„Ø§
```

### After Improvement
```
ÙŠÙØ¹Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Artificial Intelligence) Ù…Ù† Ø£Ù‡Ù… Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ø§Ù„ØªÙŠ ØªØ³Ù‡Ù… Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø­ÙˆØ¸ ÙÙŠ Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„ØªÙ‚Ù†ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ ÙˆØ²ÙŠØ§Ø¯Ø© ÙØ±Øµ Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø± ÙˆØ§Ù„Ù†Ù…Ùˆ ÙÙŠ Ù…Ø®ØªÙ„Ù Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª.

ÙŠØ¤Ø¯ÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¯ÙˆØ±Ø§Ù‹ Ù…Ù‡Ù…Ø§Ù‹ ÙÙŠ Ø±ÙØ¹ Ø§Ù„Ø¬ÙˆØ¯Ø©ØŒ ÙˆØ²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¥Ù…ÙƒØ§Ù†Ø§Øª ÙˆÙƒÙØ§Ø¡Ø© Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ©.
```

## ğŸ› ï¸ Troubleshooting

### Issue: API Not Responding
```bash
# Check API health
curl http://localhost:5001/health
```

### Issue: Text Too Short
```python
# Increase minimum length
payload = {
    "query": "Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
    "min_length": 1000  # Instead of 100
}
```

### Issue: Duplicate Content
- System automatically removes duplicates
- Can adjust similarity threshold in code

## ğŸ“ˆ Future Improvements

- [ ] Google search integration
- [ ] Advanced linguistic filtering
- [ ] Multi-language support
- [ ] Enhanced duplicate detection algorithm
- [ ] Web interface

## ğŸ¤ Contributing

We welcome contributions! Please:

1. Fork the project
2. Create a new branch
3. Make your changes
4. Submit a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Farouk568-f/text-site-ai-extractor&type=Date)](https://star-history.com/#Farouk568-f/text-site-ai-extractor&Date)

---

**ğŸ’¡ Tip**: Use `min_length: 1000` to get complete and clean content as requested!

## ğŸ“ Support

If you have any questions or need help, please open an issue on GitHub.

---

Made with â¤ï¸ for Arabic text processing
